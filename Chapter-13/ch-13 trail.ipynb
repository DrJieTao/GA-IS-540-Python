{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering applied to image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first example applies hierarchical clustering to a 2D image and attempts to produce a spacially constrained image segmentation.\n",
    "\n",
    "Source: http://scikit-learn.org/stable/auto_examples/cluster/plot_lena_ward_segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time as time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "from sklearn.cluster import ward_tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "###############################################################################\n",
    "# Generate data\n",
    "lena = sp.misc.face()\n",
    "# Downsample the image by a factor of 4\n",
    "#lena = lena[::2, ::2] + lena[1::2, ::2] + lena[::2, 1::2] + lena[1::2, 1::2]\n",
    "lena = lena[::1, ::1] + lena[0::1, ::1] + lena[::1, 0::1] + lena[0::1, 0::1]\n",
    "X = np.reshape(lena, (-1, 1))\n",
    "\n",
    "###############################################################################\n",
    "# Define the structure A of the data. Pixels connected to their neighbors.\n",
    "connectivity = grid_to_graph(*lena.shape)\n",
    "\n",
    "###############################################################################\n",
    "# Compute clustering\n",
    "st = time.time()\n",
    "n_clusters = 15  # number of regions\n",
    "ward = ward_tree(X,n_clusters=n_clusters, connectivity=connectivity)#.fit(X)\n",
    "#label = np.reshape(ward.labels, lena.shape)\n",
    "\n",
    "###############################################################################\n",
    "# Plot the results on an image\n",
    "plt.figure(1,figsize=(5, 5))\n",
    "plt.imshow(lena,cmap=pl.cm.gray); pl.xticks(()); pl.yticks(())\n",
    "\n",
    "plt.figure(2,figsize=(5, 5))\n",
    "plt.imshow(lena); pl.xticks(()); pl.yticks(())\n",
    "plt.figure(3,figsize=(5, 5))\n",
    "plt.imshow(lena, cmap=pl.cm.gray)\n",
    "\n",
    "for l in range(n_clusters):\n",
    "    pl.contour(#label == l, \n",
    "                 contours=1,colors=[pl.cm.spectral(l / float(n_clusters)), ])\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Reducing the number of colors with K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examlpe performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.\n",
    "\n",
    "In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.\n",
    "\n",
    "For comparison, a quantized image using a random codebook (colors picked up randomly) is also shown.\n",
    "\n",
    "Source: http://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that pl.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1]\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time.time()\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time.time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0)[:n_colors + 1]\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time.time()\n",
    "dist = euclidean_distances(codebook_random, image_array, squared=True)\n",
    "labels_random = dist.argmin(axis=0)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "\n",
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    d = codebook.shape[1]\n",
    "    image = np.zeros((w, h, d))\n",
    "    label_idx = 0\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            image[i][j] = codebook[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return image\n",
    "\n",
    "# Display all results, alongside original image\n",
    "plt.figure(1,figsize=(10, 6))\n",
    "plt.clf()\n",
    "ax = pl.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Original image (96,615 colors)')\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2,figsize=(10, 6))\n",
    "plt.clf()\n",
    "ax = pl.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Quantized image (64 colors, K-Means)')\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3,figsize=(10, 6))\n",
    "plt.clf()\n",
    "ax = pl.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Quantized image (64 colors, Random)')\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
